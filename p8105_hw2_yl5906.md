p8105_hw2_yl5906
================
Yujie Li
2025-09-28

\#question 1

``` r
#clean pols-month data
pols_month <- read_csv("pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>%
  mutate(
    month = month.name[month],
    president = if_else(prez_gop == 1, "gop", "dem")
  ) %>%
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#clean snp data  
snp <- read_csv("snp.csv") %>%
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>%
  mutate(
    year = if_else(year < 50, year + 2000, year + 1900),
    month = month.name[month]
  ) %>%
  select(year, month, close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#clean unemployment data
unemployment <- read_csv("unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month_short", values_to = "unemployment_rate") %>%
  mutate(month = month.name[match(month_short, month.abb)]) %>%
  select(year = Year, month, unemployment_rate)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#combine data sets
final_data <- pols_month %>%
  left_join(snp, by = c("year", "month")) %>%
  left_join(unemployment, by = c("year", "month"))

#show final data and description
glimpse(final_data)
```

    ## Rows: 822
    ## Columns: 11
    ## $ year              <dbl> 1947, 1947, 1947, 1947, 1947, 1947, 1947, 1947, 1947…
    ## $ month             <chr> "January", "February", "March", "April", "May", "Jun…
    ## $ gov_gop           <dbl> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 22, …
    ## $ sen_gop           <dbl> 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 53, …
    ## $ rep_gop           <dbl> 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 25…
    ## $ gov_dem           <dbl> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, …
    ## $ sen_dem           <dbl> 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 48, …
    ## $ rep_dem           <dbl> 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 19…
    ## $ president         <chr> "dem", "dem", "dem", "dem", "dem", "dem", "dem", "de…
    ## $ close             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
    ## $ unemployment_rate <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3.4,…

\#data description

The pols_month dataset contains 822 observations from 1947 to 2015. Key
variables include year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, and president. it means the number of republican and
democratic governors, senators, and representatives at each time point,
also the party affiliation of the president.

The snp dataset contains 787 observations from 1950 to 2015. Key
variables include year, month, and close. it means the closing values of
the SP stock index associated with each date.

The unemployment dataset contains 816 observations from 1948 to 2015.
Key variables include year, month, and unemployment_rate.

The resulting merged dataset has 822 observations and 11 variables,
spanning from 1947 to 2015. Key variables include year, month, gov_gop,
sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, and
unemployment_rate.

\#question 2

``` r
#clean Mr Trash wheel data
mr_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Mr. Trash Wheel",
  range = "A2:N586"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.numeric(year),
    trash_wheel = "Mr. Trash Wheel"
  )

#clean professor trash wheel data
prof_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Professor Trash Wheel",
  range = "A2:M108"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.numeric(year),
         trash_wheel = "Professor Trash Wheel")

#clean Gwynnda data
gwynnda_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:L157"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.numeric(year),
         trash_wheel = "Gwynnda")

#common columns and combine data set
common_cols <- intersect(intersect(names(mr_trash_wheel), names(prof_trash_wheel)), 
                        names(gwynnda_trash_wheel))

combined_trash_wheel <- bind_rows(
  mr_trash_wheel %>% select(all_of(common_cols)),
  prof_trash_wheel %>% select(all_of(common_cols)),
  gwynnda_trash_wheel %>% select(all_of(common_cols))
)

#show the combined data set
glimpse(combined_trash_wheel)
```

    ## Rows: 845
    ## Columns: 13
    ## $ dumpster           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …
    ## $ month              <chr> "May", "May", "May", "May", "May", "May", "May", "M…
    ## $ year               <dbl> 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 201…
    ## $ date               <dttm> 2014-05-16, 2014-05-16, 2014-05-16, 2014-05-17, 20…
    ## $ weight_tons        <dbl> 4.31, 2.74, 3.45, 3.10, 4.06, 2.71, 1.91, 3.70, 2.5…
    ## $ volume_cubic_yards <dbl> 18, 13, 15, 15, 18, 13, 8, 16, 14, 18, 15, 19, 15, …
    ## $ plastic_bottles    <dbl> 1450, 1120, 2450, 2380, 980, 1430, 910, 3580, 2400,…
    ## $ polystyrene        <dbl> 1820, 1030, 3100, 2730, 870, 2140, 1090, 4310, 2790…
    ## $ cigarette_butts    <dbl> 126000, 91000, 105000, 100000, 120000, 90000, 56000…
    ## $ plastic_bags       <dbl> 584, 496, 1080, 896, 368, 672, 416, 1552, 984, 448,…
    ## $ wrappers           <dbl> 1162, 874, 2032, 1971, 753, 1144, 692, 3015, 1988, …
    ## $ homes_powered      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
    ## $ trash_wheel        <chr> "Mr. Trash Wheel", "Mr. Trash Wheel", "Mr. Trash Wh…

``` r
#calculate professor trash wheel total weight
prof_total_weight <- combined_trash_wheel %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  summarise(total = sum(weight_tons, na.rm = TRUE)) %>%
  pull(total)

#calculate Gwynnda cigarette butts june 2022
gwynnda_cigarettes <- combined_trash_wheel %>%
  filter(trash_wheel == "Gwynnda", year == 2022, month == "June") %>%
  summarise(total = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total)

cat("Professor Trash Wheel total weight:", prof_total_weight, "tons\n")
```

    ## Professor Trash Wheel total weight: 216.26 tons

``` r
cat("Gwynnda cigarette butts in June 2022:", gwynnda_cigarettes, "\n")
```

    ## Gwynnda cigarette butts in June 2022: 18120

\#data description

The Mr Trash Wheel data contains 584 observations from 2014 to 2023. The
Professor Trash Wheel dataset contains 106 observations from 2017 to
2023. The Gwynnda data contains 155 observations from 2021 to 2023. The
combined dataset has 845 observations and 13 variables. Key variables
include dumpster, month, year, date, weight_tons, volume_cubic_yards,
and various trash types like plastic_bottles, cigarette_butts, and
sports_balls.

so as the code calculation the total weight collected by Professor Trash
Wheel was 216.26 tons. Gwynnda collected 1.812^{4} cigarette butts in
june 2022.

\#question 3

``` r
#normalize ZIP to 5 digit string
norm_zip <- function(x) x |> as.character() |> stringr::str_extract("\\d{5}") |> stringr::str_pad(5, pad = "0")

#Read ZIP Codes
zip_tbl <- read_csv("Zip Codes.csv", show_col_types = FALSE) |>
  transmute(
    zip = norm_zip(ZipCode),
    neighborhood = Neighborhood
  ) |>
  distinct()

#Read ZORI and we need reshape wide to long. derive borough from CountyName
borough_from_county <- function(x) dplyr::case_when(
  stringr::str_detect(x, regex("^new york", TRUE)) ~ "Manhattan",
  stringr::str_detect(x, regex("^kings",    TRUE)) ~ "Brooklyn",
  stringr::str_detect(x, regex("^queens",   TRUE)) ~ "Queens",
  stringr::str_detect(x, regex("^bronx",    TRUE)) ~ "Bronx",
  stringr::str_detect(x, regex("^richmond", TRUE)) ~ "Staten Island",
  TRUE ~ NA_character_
)

zori_long <- read_csv("Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", show_col_types = FALSE) |>
  pivot_longer(cols = matches("^\\d{4}-\\d{2}-\\d{2}$"),
               names_to = "date", values_to = "price") |>
  filter(!is.na(price)) |>
  mutate(
    zip     = norm_zip(RegionName),
    date    = ymd(date),
    borough = borough_from_county(CountyName)
  ) |>
  select(zip, date, price, borough)

#combine data set
tidy_df <- zori_long |>
  left_join(zip_tbl, by = "zip") |>
  arrange(zip, date)


#answer 1 brief description
cat("Total observations:", nrow(tidy_df), "\n")
```

    ## Total observations: 10450

``` r
cat("Unique ZIP codes:", n_distinct(tidy_df$zip), "\n")
```

    ## Unique ZIP codes: 149

``` r
cat("Unique neighborhoods:", n_distinct(na.omit(tidy_df$neighborhood)), "\n")
```

    ## Unique neighborhoods: 42

``` r
#answer 2 ZIPs present in ZIP Codes but missing in Zillow ----
zips_only_in_zip <- zip_tbl |>
  anti_join(distinct(zori_long, zip), by = "zip")
print(zips_only_in_zip)
```

    ## # A tibble: 171 × 2
    ##    zip   neighborhood              
    ##    <chr> <chr>                     
    ##  1 10464 Southeast Bronx           
    ##  2 10474 Hunts Point and Mott Haven
    ##  3 10475 Northeast Bronx           
    ##  4 10499 <NA>                      
    ##  5 10550 <NA>                      
    ##  6 10704 <NA>                      
    ##  7 10705 <NA>                      
    ##  8 10803 <NA>                      
    ##  9 11202 <NA>                      
    ## 10 11224 Southern Brooklyn         
    ## # ℹ 161 more rows

``` r
#answer 3 Top 10 ZIP with largest drop in 2020 jan to 2021 jan
d2020 <- tidy_df |> filter(year(date)==2020, month(date)==1) |> summarise(d=max(date)) |> pull(d)
d2021 <- tidy_df |> filter(year(date)==2021, month(date)==1) |> summarise(d=max(date)) |> pull(d)

top10_drops <- tidy_df |>
  filter(date %in% c(d2020, d2021)) |>
  select(zip, borough, neighborhood, date, price) |>
  pivot_wider(names_from = date, values_from = price) |>
  filter(!is.na(.data[[as.character(d2020)]]), !is.na(.data[[as.character(d2021)]])) |>
  transmute(
    zip, borough, neighborhood,
    price2020 = .data[[as.character(d2020)]],
    price2021 = .data[[as.character(d2021)]],
    drop_abs  = price2021 - price2020,
    drop_pct  = (price2021 - price2020) / price2020
  ) |>
  arrange(drop_abs) |>
  head(10)

print(top10_drops)
```

    ## # A tibble: 10 × 7
    ##    zip   borough   neighborhood            price2020 price2021 drop_abs drop_pct
    ##    <chr> <chr>     <chr>                       <dbl>     <dbl>    <dbl>    <dbl>
    ##  1 10007 Manhattan Lower Manhattan             6334.     5422.    -913.   -0.144
    ##  2 10069 Manhattan <NA>                        4623.     3875.    -748.   -0.162
    ##  3 10009 Manhattan Lower East Side             3406.     2692.    -714.   -0.210
    ##  4 10016 Manhattan Gramercy Park and Murr…     3731.     3019.    -712.   -0.191
    ##  5 10001 Manhattan Chelsea and Clinton         4108.     3398.    -710.   -0.173
    ##  6 10002 Manhattan Lower East Side             3645.     2935.    -710.   -0.195
    ##  7 10004 Manhattan Lower Manhattan             3150.     2444.    -706.   -0.224
    ##  8 10038 Manhattan Lower Manhattan             3573.     2876.    -698.   -0.195
    ##  9 10012 Manhattan Greenwich Village and …     3629.     2942.    -686.   -0.189
    ## 10 10010 Manhattan Gramercy Park and Murr…     3697.     3012.    -685.   -0.185

\#data description summary

So there are 10450 observations, 149 unique ZIP codes and 42 unique
neighborhood. Like 10464(Southeast Bronx) and 10474，10475，11224
etc.present in ZIP Codes but missing in Zillow. These zip maybe use for
industrialize area or other place do not contain residences.The areas
that experienced the largest decline were the central districts of
Manhattan and the neighborhoods near some office areas. This was because
during the pandemic, people were working from home or losing their jobs,
resulting in a decrease in the number of tenants in these central areas.
