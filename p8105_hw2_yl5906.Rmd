---
title: "p8105_hw2_yl5906"
author: "Yujie Li"
date: "2025-09-28"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(janitor)
```

#Question 1

```{r}
#clean pols-month data
pols_month <- read_csv("pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>%
  mutate(
    month = month.name[month],
    president = if_else(prez_gop == 1, "gop", "dem")
  ) %>%
  select(-prez_dem, -prez_gop, -day)

#clean snp data  
snp <- read_csv("snp.csv") %>%
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>%
  mutate(
    year = if_else(year < 50, year + 2000, year + 1900),
    month = month.name[month]
  ) %>%
  select(year, month, close)

#clean unemployment data
unemployment <- read_csv("unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month_short", values_to = "unemployment_rate") %>%
  mutate(month = month.name[match(month_short, month.abb)]) %>%
  select(year = Year, month, unemployment_rate)

#combine data sets
final_data <- pols_month %>%
  left_join(snp, by = c("year", "month")) %>%
  left_join(unemployment, by = c("year", "month"))

#show final data and description
glimpse(final_data)

```

##data description

The pols_month dataset contains `r nrow(pols_month)` observations from `r min(pols_month$year)` to `r max(pols_month$year)`. Key variables include year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, and president. it means the number of republican and democratic governors, senators, and representatives at each time point, also the party affiliation of the president.

The snp dataset contains `r nrow(snp)` observations from `r min(snp$year)` to `r max(snp$year)`. Key variables include year, month, and close. it means the closing values of the SP stock index associated with each date.

The unemployment dataset contains `r nrow(unemployment)` observations from `r min(unemployment$year)` to `r max(unemployment$year)`. Key variables include year, month, and unemployment_rate.

The resulting merged dataset has `r nrow(final_data)` observations and `r ncol(final_data)` variables, spanning from `r min(final_data$year)` to `r max(final_data$year)`. Key variables include year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, and unemployment_rate.

<br><br>



#Question 2

```{r}
#clean Mr Trash wheel data
mr_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Mr. Trash Wheel",
  range = "A2:N586"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.numeric(year),
    trash_wheel = "Mr. Trash Wheel"
  )

#clean professor trash wheel data
prof_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Professor Trash Wheel",
  range = "A2:M108"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.numeric(year),
         trash_wheel = "Professor Trash Wheel")

#clean Gwynnda data
gwynnda_trash_wheel <- read_excel(
  "Trash Wheel Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:L157"
) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.numeric(year),
         trash_wheel = "Gwynnda")

#common columns and combine data set
common_cols <- intersect(intersect(names(mr_trash_wheel), names(prof_trash_wheel)), 
                        names(gwynnda_trash_wheel))

combined_trash_wheel <- bind_rows(
  mr_trash_wheel %>% select(all_of(common_cols)),
  prof_trash_wheel %>% select(all_of(common_cols)),
  gwynnda_trash_wheel %>% select(all_of(common_cols))
)

#show the combined data set
glimpse(combined_trash_wheel)

#calculate professor trash wheel total weight
prof_total_weight <- combined_trash_wheel %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  summarise(total = sum(weight_tons, na.rm = TRUE)) %>%
  pull(total)

#calculate Gwynnda cigarette butts june 2022
gwynnda_cigarettes <- combined_trash_wheel %>%
  filter(trash_wheel == "Gwynnda", year == 2022, month == "June") %>%
  summarise(total = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total)

cat("Professor Trash Wheel total weight:", prof_total_weight, "tons\n")
cat("Gwynnda cigarette butts in June 2022:", gwynnda_cigarettes, "\n")
```

##data description

The Mr Trash Wheel data contains `r nrow(mr_trash_wheel)` observations from `r min(mr_trash_wheel$year)` to `r max(mr_trash_wheel$year)`. The Professor Trash Wheel dataset contains `r nrow(prof_trash_wheel)` observations from `r min(prof_trash_wheel$year)` to `r max(prof_trash_wheel$year)`. The Gwynnda data contains `r nrow(gwynnda_trash_wheel)` observations from `r min(gwynnda_trash_wheel$year)` to `r max(gwynnda_trash_wheel$year)`. The combined dataset has `r nrow(combined_trash_wheel)` observations and `r ncol(combined_trash_wheel)` variables. Key variables include dumpster, month, year, date, weight_tons, volume_cubic_yards, and various trash types like plastic_bottles, cigarette_butts, and sports_balls.

so as the code calculation the total weight collected by Professor Trash Wheel was `r prof_total_weight` tons. Gwynnda collected `r gwynnda_cigarettes` cigarette butts in june 2022.

<br><br>



#Question 3

```{r}
#normalize ZIP to 5 digit string
norm_zip <- function(x) x |> as.character() |> stringr::str_extract("\\d{5}") |> stringr::str_pad(5, pad = "0")

#Read ZIP Codes
zip_tbl <- read_csv("Zip Codes.csv", show_col_types = FALSE) |>
  transmute(
    zip = norm_zip(ZipCode),
    neighborhood = Neighborhood
  ) |>
  distinct()

#Read ZORI and we need reshape wide to long. derive borough from CountyName
borough_from_county <- function(x) dplyr::case_when(
  stringr::str_detect(x, regex("^new york", TRUE)) ~ "Manhattan",
  stringr::str_detect(x, regex("^kings",    TRUE)) ~ "Brooklyn",
  stringr::str_detect(x, regex("^queens",   TRUE)) ~ "Queens",
  stringr::str_detect(x, regex("^bronx",    TRUE)) ~ "Bronx",
  stringr::str_detect(x, regex("^richmond", TRUE)) ~ "Staten Island",
  TRUE ~ NA_character_
)

zori_long <- read_csv("Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", show_col_types = FALSE) |>
  pivot_longer(cols = matches("^\\d{4}-\\d{2}-\\d{2}$"),
               names_to = "date", values_to = "price") |>
  filter(!is.na(price)) |>
  mutate(
    zip     = norm_zip(RegionName),
    date    = ymd(date),
    borough = borough_from_county(CountyName)
  ) |>
  select(zip, date, price, borough)

#combine data set
tidy_df <- zori_long |>
  left_join(zip_tbl, by = "zip") |>
  arrange(zip, date)


#answer 1 brief description
cat("Total observations:", nrow(tidy_df), "\n")
cat("Unique ZIP codes:", n_distinct(tidy_df$zip), "\n")
cat("Unique neighborhoods:", n_distinct(na.omit(tidy_df$neighborhood)), "\n")


#answer 2 ZIPs present in ZIP Codes but missing in Zillow ----
zips_only_in_zip <- zip_tbl |>
  anti_join(distinct(zori_long, zip), by = "zip")
print(zips_only_in_zip)


#answer 3 Top 10 ZIP with largest drop in 2020 jan to 2021 jan
d2020 <- tidy_df |> filter(year(date)==2020, month(date)==1) |> summarise(d=max(date)) |> pull(d)
d2021 <- tidy_df |> filter(year(date)==2021, month(date)==1) |> summarise(d=max(date)) |> pull(d)

top10_drops <- tidy_df |>
  filter(date %in% c(d2020, d2021)) |>
  select(zip, borough, neighborhood, date, price) |>
  pivot_wider(names_from = date, values_from = price) |>
  filter(!is.na(.data[[as.character(d2020)]]), !is.na(.data[[as.character(d2021)]])) |>
  transmute(
    zip, borough, neighborhood,
    price2020 = .data[[as.character(d2020)]],
    price2021 = .data[[as.character(d2021)]],
    drop_abs  = price2021 - price2020,
    drop_pct  = (price2021 - price2020) / price2020
  ) |>
  arrange(drop_abs) |>
  head(10)

print(top10_drops)
```


##data description

So there are 10450 observations, 149 unique ZIP codes and 42 unique neighborhood.
Like 10464(Southeast Bronx) and 10474，10475，11224 etc. present in ZIP Codes but missing in Zillow. These zip maybe use for industrialize area or other place do not contain residences.The areas that experienced the largest decline were the central districts of Manhattan and the neighborhoods near some office areas. This was because during the pandemic, people were working from home or losing their jobs, resulting in a decrease in the number of tenants in these central areas.

